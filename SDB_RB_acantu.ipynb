{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPrlAM6VktBwPEmzaYMZ8xV",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/cantu-a/SDB/blob/main/SDB_RB_acantu.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ABOUT:\n",
        "This workflow leverages Google Earth Engine and Python to develop satellite-derived elevation data in intertidal zones. Workflow is still messy, and this version is set for Rookery Bay, FL (original workflow on Laguna Madre, TX) and using Landsat 8 and 9 images. Interpolation via kriging does not work due to RAM issues, whereas interpolation via IDW does not perform well.\n",
        "\n",
        "This Code is nearly identical to 'SDB_LM_acantu.ipynb' but focused on Rookery Bay site.\n",
        "\n",
        "Contact info: antoniocantu91@gmail.com\n",
        "\n",
        "Citation: Cantu de Leija, A. 2025. Spatiotemporal dynamics of foraging habtiat availability for waterbirds in intertidal zones of the Gulf of Mexico. PhD Dissertation, Texas A&M University-Corpus Christi.\n",
        "\n",
        "Harte Research Institute, Texas A&M University-Corpus Christi"
      ],
      "metadata": {
        "id": "ndeeM58bbqsL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Setup Google Earth Engine"
      ],
      "metadata": {
        "id": "k0QPeYa--IeQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Install required packages\n",
        "!pip install earthengine-api geemap pykrige\n",
        "\n",
        "# Import necessary libraries\n",
        "import ee\n",
        "import geemap #for visualization\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt #for plotting and viz\n",
        "from pykrige.ok import OrdinaryKriging #for Kriging interpolation\n",
        "import folium\n",
        "\n",
        "# Authenticate and initialize GEE\n",
        "ee.Authenticate()\n",
        "ee.Initialize(project='ee-acantu') #link personal GEE account"
      ],
      "metadata": {
        "collapsed": true,
        "id": "1TFxW2xY-Q4o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. Define study area, build an Image Collection, NDWI function. Check how many images are available and adjust timefarame and cloud percentage as needed."
      ],
      "metadata": {
        "id": "uhpDqWGj_pFr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define study area (modify coordinates for your location)\n",
        "RB = ee.Geometry.Polygon(\n",
        "        [[[-81.75599789133553,25.981617386190347],\n",
        "          [-81.75668453684334,25.938401989275484],\n",
        "          [-81.68596004953865,25.832766290771165],\n",
        "          [-81.61935543528084,25.883433799519395],\n",
        "          [-81.60905575266365,25.946428905634107],\n",
        "          [-81.72647213449959,26.039007562433564],\n",
        "          [-81.79032415997217,26.056270087277465],\n",
        "          [-81.75599789133553,25.981617386190347]]]); # Rookery Bay, FL\n",
        "\n",
        "## =====================================================================================================\n",
        "# Load Sentinel-2 Image Collection (filter by cloud cover and date)\n",
        "s2_collection = ee.ImageCollection(\"COPERNICUS/S2_SR_HARMONIZED\") \\\n",
        "    .filterBounds(RB) \\\n",
        "    .filterDate('2022-01-01', '2024-12-31') \\\n",
        "    .filterMetadata('CLOUDY_PIXEL_PERCENTAGE', 'less_than', 5)\n",
        "print('# of S2 images:', s2_collection.size().getInfo())# print the number of images found in the search\n",
        "\n",
        "# Function to make landsat Bands compatible\n",
        "def harmonize_landsat(image, sensor):\n",
        "    # Harmonize band names to match: [Blue, Green, Red, NIR, SWIR1, SWIR2]\n",
        "    if sensor == 'L7':\n",
        "        bands = ['B1', 'B2', 'B3', 'B4', 'B5', 'B7']  # Landsat 7 (no B6)\n",
        "    else:  # L8 or L9\n",
        "        bands = ['B2', 'B3', 'B4', 'B5', 'B6', 'B7']\n",
        "\n",
        "    common_names = ['B2', 'B3', 'B4', 'B5', 'B6', 'B7']\n",
        "\n",
        "    image = image.select(bands, common_names)\n",
        "    return image.clip(RB)\n",
        "\n",
        "l7 = ee.ImageCollection(\"LANDSAT/LE07/C02/T1_TOA\") \\\n",
        "    .filterBounds(RB) \\\n",
        "    .filterDate('2022-01-01', '2024-12-31') \\\n",
        "    .filterMetadata('CLOUD_COVER', 'less_than', 5) \\\n",
        "    .map(lambda img: harmonize_landsat(img, 'L7'))\n",
        "#print('# of L7 images:', l7.size().getInfo())# print the number of images found in the search\n",
        "\n",
        "l8 = ee.ImageCollection(\"LANDSAT/LC08/C02/T1_TOA\") \\\n",
        "    .filterBounds(RB) \\\n",
        "    .filterDate('2022-01-01', '2024-12-31') \\\n",
        "    .filterMetadata('CLOUD_COVER', 'less_than', 5) \\\n",
        "    .map(lambda img: harmonize_landsat(img, 'L8'))\n",
        "#print('# of L8 images:', l8.size().getInfo())# print the number of images found in the search\n",
        "\n",
        "l9 = ee.ImageCollection(\"LANDSAT/LC09/C02/T1_TOA\") \\\n",
        "    .filterBounds(RB) \\\n",
        "    .filterDate('2022-01-01', '2024-12-31') \\\n",
        "    .filterMetadata('CLOUD_COVER', 'less_than', 5) \\\n",
        "    .map(lambda img: harmonize_landsat(img, 'L9'))\n",
        "#print('# of L9 images:', l9.size().getInfo())# print the number of images found in the search\n",
        "'''\n",
        "# merge landsat collections\n",
        "l_collection = l7.merge(l8).merge(l9);\n",
        "print('# of Landsat images:', l_collection.size().getInfo())# print the number of images found in the search\n",
        "#first_img = l_collection.first()\n",
        "#print(first_img.getInfo())\n",
        "'''\n",
        "# alternatively, merge only L8 and 9\n",
        "l_collection = l8.merge(l9);\n",
        "print('# of Landsat images:', l_collection.size().getInfo())# print the number of images found in the search\n",
        "\n",
        "## ====================================================================================================\n",
        "\n",
        "# Function to compute NDWI and MNDWI\n",
        "def ndwi(image):\n",
        "    ndwi_image = image.normalizedDifference(['B5', 'B3']).rename('NDWI')  # (Green - NIR) / (Green + NIR)\n",
        "    return ndwi_image.copyProperties(image, ['system:time_start'])\n",
        "\n",
        "def mndwi(image):\n",
        "    mndwi_image = image.normalizedDifference(['B7', 'B3']).rename('MNDWI')  # (Green - SWIR1) / (Green + SWIR1)\n",
        "    return mndwi_image.copyProperties(image, ['system:time_start'])\n",
        "\n",
        "# this function masked areas where you have values lower or equal to 0.4\n",
        "def mask_land (image):\n",
        "  return image.updateMask(image.lte(0.4));\n",
        "\n",
        "# Function to clip to aoi\n",
        "def clip_aoi(image):\n",
        "  return image.clip(RB)\n",
        "\n"
      ],
      "metadata": {
        "collapsed": true,
        "id": "TncbCkXuAJ9p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Note: Landsat 7 images are corrupted, thus not usable as on April 2025."
      ],
      "metadata": {
        "id": "AxFnMxDUgpsi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "2.1 Map NDWI function to image collection and compute STD"
      ],
      "metadata": {
        "id": "lHtHcQvlo4zQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Using NDWI\n",
        "'''\n",
        "# SENTINEL\n",
        "# Apply the NDWI function to the image collection\n",
        "s2_ndwi = s2_collection.map(ndwi)\n",
        "s2_ndwi = s2_ndwi.map(clip_aoi)\n",
        "#s2_ndwi = s2_ndwi.map(mask_land)\n",
        "\n",
        "# Compute standard deviation to map intertidal areas\n",
        "NDWI_STD=s2_ndwi.reduce(ee.Reducer.stdDev());# Now the entire collection was reduced to one-single image showing STD\n",
        "\n",
        "#Mask the non-watery parts of the image, where NDWI < 0.4.\n",
        "stdMasked = NDWI_STD.updateMask(NDWI_STD.gte(0.32).And(NDWI_STD.lte(0.42)));#EQ(\"=\"), GTE(\">=\"), GT(\">\"), LT(\"<\"), LTE(\"<=\");\n",
        "zones=NDWI_STD.gte(0.32).And(NDWI_STD.lte(0.40))\n",
        "zones=zones.updateMask(zones.neq(0))\n",
        "zones=zones.updateMask(zones.neq(0))\n",
        "'''\n",
        "# LANDSAT\n",
        "\n",
        "# Apply the NDWI function to the image collection\n",
        "l_ndwi = l_collection.map(ndwi)\n",
        "l_ndwi = l_ndwi.map(clip_aoi)\n",
        "#l_ndwi = l_ndwi.map(mask_land)\n",
        "first_img = l_ndwi.first()\n",
        "print(first_img.getInfo())\n",
        "\n",
        "# Compute standard deviation to map intertidal areas\n",
        "NDWI_STD = l_ndwi.reduce(ee.Reducer.stdDev());# Now the entire collection was reduced to one-single image showing STD\n",
        "\n",
        "#Mask the non-watery parts of the image, where NDWI > 0.21\n",
        "stdMasked = NDWI_STD.updateMask(NDWI_STD.gte(0.22)); #.And(NDWI_STD.lte(0.45)));#EQ(\"=\"), GTE(\">=\"), GT(\">\"), LT(\"<\"), LTE(\"<=\");\n",
        "\n",
        "\n",
        "## Using MNDWI\n",
        "'''\n",
        "# SENTINEL\n",
        "# Apply the MNDWI function to the image collection\n",
        "s2_mndwi = s2_collection.map(mndwi)\n",
        "s2_mndwi = s2_mndwi.map(clip_aoi)\n",
        "\n",
        "# Compute standard deviation to map intertidal areas\n",
        "MNDWI_STD=s2_mndwi.reduce(ee.Reducer.stdDev())# Now the entire collection was reduced to one-single image showing STD\n",
        "\n",
        "#Mask the non-watery parts of the image, where NDWI < 0.4.\n",
        "stdMasked = MNDWI_STD.updateMask(MNDWI_STD.gte(0.25).And(MNDWI_STD.lte(0.45)));#EQ(\"=\"), GTE(\">=\"), GT(\">\"), LT(\"<\"), LTE(\"<=\");\n",
        "zones=MNDWI_STD.gte(0.2).And(MNDWI_STD.lte(0.35))\n",
        "zones=zones.updateMask(zones.neq(0))\n",
        "zones=zones.updateMask(zones.neq(0))\n",
        "\n",
        "\n",
        "# LANDSAT\n",
        "# Apply the MNDWI function to the image collection\n",
        "l9_mndwi = l9_collection.map(mndwi)\n",
        "l9_mndwi = l9_mndwi.map(clip_aoi)\n",
        "\n",
        "# Compute standard deviation to map intertidal areas\n",
        "MNDWI_STD=l9_mndwi.reduce(ee.Reducer.stdDev())# Now the entire collection was reduced to one-single image showing STD\n",
        "\n",
        "#Mask the non-watery parts of the image, where NDWI < 0.4.\n",
        "stdMasked = MNDWI_STD.updateMask(MNDWI_STD.gte(0.25)); #.And(MNDWI_STD.lte(0.35)));#EQ(\"=\"), GTE(\">=\"), GT(\">\"), LT(\"<\"), LTE(\"<=\");\n",
        "zones=MNDWI_STD.gte(0.2).And(MNDWI_STD.lte(0.35))\n",
        "zones=zones.updateMask(zones.neq(0))\n",
        "zones=zones.updateMask(zones.neq(0))\n",
        "'''\n",
        "\n",
        "# Assume 'image' is your ee.Image\n",
        "crs_info = stdMasked.projection()\n",
        "print('CRS:', crs_info.getInfo())"
      ],
      "metadata": {
        "id": "5g-TX39Mo_5T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### NOTES:\n",
        "- In Alafia Bank, Landsat images work best with NDWI gte 0.23. Dates = Jan 2022 - Dec 2023\n",
        "- In Honemoon Island, Landsat images work best with NDWI gte 0.21, but some L7 images may be corrupted. Dates = Jan 2022 - Dec 2023\n",
        "- In Laguna Madre, Landsat images work best with NDWI gte 0.21, dates can be extended to Jan 2022- Dec 2024\n",
        "- In Rookery Bay, Landsat images work best with NDWI gte 0.23 (Jan 22 - Dec 24)\n",
        "    "
      ],
      "metadata": {
        "id": "4vopYMo0ofLu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "2.2 Visualize intertidal areas based on NDWI STD"
      ],
      "metadata": {
        "id": "lqpxfCfBq-ZE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Set visualization parameters.\n",
        "palette = ['blue','yellow'];\n",
        "vis_params = {\n",
        "              'min': 0.21,\n",
        "              'max': 0.4,\n",
        "              'dimensions': 500,\n",
        "              'palette':palette,\n",
        "              };\n",
        "\n",
        "# Using geemap\n",
        "# Initialize map\n",
        "Map = geemap.Map(basemap='SATELLITE')\n",
        "Map.centerObject(RB, 12)\n",
        "\n",
        "# Add standard deviation of NDWI to highlight intertidal areas\n",
        "Map.addLayer(stdMasked, vis_params, 'Intertidal mask', shown=True)\n",
        "\n",
        "# Display map\n",
        "Map\n"
      ],
      "metadata": {
        "id": "-mqAwPZtrC3U",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "2.3 Masking and exporting intertidal areas as vector"
      ],
      "metadata": {
        "id": "wOHNyBoUIAnS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#mask areas with STD values greater than .21\n",
        "zones=NDWI_STD.gte(0.22)\n",
        "zones=zones.updateMask(zones.neq(0))\n",
        "\n",
        "\n",
        "\n",
        "# creating vector polygon representing the intertidal zone for the study area\n",
        "# use 'stdMasked' instead of zones if want to clip to intertidal extent only\n",
        "vectors=zones.addBands(zones).reduceToVectors(\n",
        "  crs= 'EPSG:4326', # always double check\n",
        "  scale= 10,\n",
        "  #crsTransform=[60, 0, 399960, 0, -60, 5900020],\n",
        "  geometryType= 'polygon',\n",
        "  labelProperty= 'stdMasked',\n",
        "  eightConnected= False,\n",
        "  geometry= RB, # change location accordingly\n",
        "  maxPixels=100e9,\n",
        "  geometryInNativeProjection=True,\n",
        "  reducer= ee.Reducer.mean(),\n",
        ")\n",
        "\n",
        "print(vectors.getInfo()) # showing vectors propertiers\n",
        "print('numbers of vectors identified: ' + str(vectors.size().getInfo()))# print the numbers of vectors identified"
      ],
      "metadata": {
        "id": "6_ntuuRhIHJp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###2.4 Create imageCollection with ndwi that will later be used for Otsu thresholding"
      ],
      "metadata": {
        "id": "jcS_kSFwExi1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "'''\n",
        "# function to clip areas into identified vectors\n",
        "def clip_image2 (image):\n",
        "  return image.clip(vectors)\n",
        "\n",
        "# Clipping all images in the collection into the vector areas\n",
        "NWI2=l_collection.map(ndwi);\n",
        "\n",
        "intertidal_zones=NWI2.map(clip_image2)\n",
        "'''\n",
        "# ImageCollection without clipping to intertidal extent only\n",
        "intertidal_zones=l_collection.map(ndwi);\n",
        "\n",
        "#filter image that messes up the otsu threshold\n",
        "intertidal_zones = intertidal_zones.filter(ee.Filter.neq('system:index', '1_LC08_016042_20220115'))\n",
        "\n",
        "first_image = intertidal_zones.first()\n",
        "print(first_image.getInfo())\n",
        "\n",
        "# Visualizing vectors for intertidal areas\n",
        "# Set visualization parameters.\n",
        "palette = ['blue','yellow', 'red'];\n",
        "#palette= ['0000FF', '00FF00', 'FF0000']\n",
        "vis_params = {\n",
        "              'min': -0.6,\n",
        "              'max': 0.5,\n",
        "              'dimensions': 500,\n",
        "              'palette':palette,\n",
        "              };\n",
        "Map.addLayer(intertidal_zones, vis_params, 'Intertidal Zones')\n",
        "Map"
      ],
      "metadata": {
        "id": "xa2TIUd-FBSx",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "2.5 Export vectors as .shp and export NDWI image clipped to intertidal areas\n",
        "\n",
        "######*This is optional step to create a shapefile of intertidal zones identified via NDWI_STD*"
      ],
      "metadata": {
        "id": "XJUpik2AQrPQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# This code is to export a shapefile of intertidal extent after it has been converted to a featureCollection\n",
        "\n",
        "'''\n",
        "task= ee.batch.Export.table.toDrive(collection= vectors, description='RB_intertidal_zones', fileFormat= 'SHP');#  we need to create a batch in order to export ee images using python\n",
        "task.start()# starting the batch\n",
        "#vectors.getInfo()\n",
        "\n",
        "#task.status # check the current status of your exportation\n",
        "'''"
      ],
      "metadata": {
        "id": "oK7D3t5LRBTN",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# =========== CHECK POINT ========================================="
      ],
      "metadata": {
        "id": "ZOVPBBadTB_M"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 3. Waterline extraction (Otsu thresholding)"
      ],
      "metadata": {
        "id": "Uz0xWeSNNgAe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import datetime\n",
        "from skimage import filters\n",
        "\n",
        "# Otsu function adapted to run inside Earth Engine\n",
        "def otsu_threshold(histogram):\n",
        "    counts = ee.Array(ee.Dictionary(histogram).get('histogram'))\n",
        "    means = ee.Array(ee.Dictionary(histogram).get('bucketMeans'))\n",
        "    total = counts.reduce(ee.Reducer.sum(), [0]).get([0])\n",
        "    sum_total = means.multiply(counts).reduce(ee.Reducer.sum(), [0]).get([0])\n",
        "\n",
        "    def compute(i):\n",
        "        counts_slice = counts.slice(0, 0, i.add(1))\n",
        "        means_slice = means.slice(0, 0, i.add(1))\n",
        "        w_bg = counts_slice.reduce(ee.Reducer.sum(), [0]).get([0])\n",
        "        sum_bg = means_slice.multiply(counts_slice).reduce(ee.Reducer.sum(), [0]).get([0])\n",
        "        mean_bg = ee.Number(sum_bg).divide(w_bg)\n",
        "        w_fg = ee.Number(total).subtract(w_bg)\n",
        "        sum_fg = ee.Number(sum_total).subtract(sum_bg)\n",
        "        mean_fg = ee.Number(sum_fg).divide(w_fg)\n",
        "        between_var = w_bg.multiply(w_fg).multiply(mean_bg.subtract(mean_fg).pow(2))\n",
        "        return between_var\n",
        "\n",
        "    # Modification: Get the length of the histogram counts as a number\n",
        "    num_bins = counts.length().get([0]) # Get the length of counts as a number\n",
        "\n",
        "    indices = ee.List.sequence(1, num_bins.subtract(1)) # Use the numeric length\n",
        "    variances = indices.map(lambda i: compute(ee.Number(i)))\n",
        "\n",
        "    max_value = ee.List(variances).reduce(ee.Reducer.max())\n",
        "    max_idx = ee.List(variances).indexOf(max_value)\n",
        "\n",
        "    # Change: Access means using a list of indices\n",
        "    threshold = means.get([max_idx]) # Pass max_idx as a list\n",
        "    return threshold\n",
        "\n",
        "\n",
        "# Function to apply threshold to extract waterline\n",
        "def extract_waterline(image):\n",
        "    ndwi = image.select('NDWI')\n",
        "\n",
        "    histogram = ndwi.reduceRegion(\n",
        "        reducer=ee.Reducer.histogram(255),\n",
        "        geometry=RB,\n",
        "        scale=30,\n",
        "        maxPixels=1e9\n",
        "    ).get('NDWI')\n",
        "\n",
        "    # Compute threshold as a Number\n",
        "    threshold_number = ee.Algorithms.If(histogram, otsu_threshold(histogram), 0.24)\n",
        "    threshold_number = ee.Number(threshold_number)  # Ensure it is a Number\n",
        "\n",
        "    # Create threshold image for comparison\n",
        "    threshold_image = ee.Image.constant(threshold_number)\n",
        "\n",
        "    # Create binary water mask: water = 1, land = 0\n",
        "    binary = ndwi.lt(threshold_image).rename('binary')\n",
        "\n",
        "    # Return both NDWI and binary bands\n",
        "    return image.addBands(binary) \\\n",
        "                .set('otsu_threshold', threshold_number) \\\n",
        "                .copyProperties(image, ['system:time_start'])\n",
        "\n",
        "# Apply function to imageCollection\n",
        "waterline_collection = intertidal_zones.map(extract_waterline)\n",
        "print(waterline_collection.limit(5).getInfo())\n",
        "#print(waterline_collection.aggregate_array('otsu_threshold').getInfo())\n",
        "\n"
      ],
      "metadata": {
        "id": "SJL36rJuNrkN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Choose one image from your collection\n",
        "sample_image = ee.Image(intertidal_zones.first())  # Replace with a specific image if needed\n",
        "\n",
        "# Select NDWI band\n",
        "ndwi = sample_image.select('NDWI')\n",
        "\n",
        "# Compute histogram over your study region (RB)\n",
        "hist_dict = ndwi.reduceRegion(\n",
        "    reducer=ee.Reducer.histogram(255),\n",
        "    geometry=RB,\n",
        "    scale=30,\n",
        "    maxPixels=1e9\n",
        ").get('NDWI')\n",
        "\n",
        "# Get threshold\n",
        "threshold = otsu_threshold(hist_dict).getInfo()\n",
        "\n",
        "# Convert histogram to Python objects\n",
        "histogram = ee.Dictionary(hist_dict).getInfo()\n",
        "counts = histogram['histogram']\n",
        "means = histogram['bucketMeans']\n",
        "\n",
        "# Plot\n",
        "plt.figure(figsize=(8, 5))\n",
        "plt.bar(means, counts, width=(means[1] - means[0]), align='center', edgecolor='black')\n",
        "plt.axvline(x=threshold, color='red', linestyle='--', label=f'Otsu Threshold = {threshold:.2f}')\n",
        "plt.xlabel('NDWI Value')\n",
        "plt.ylabel('Pixel Count')\n",
        "plt.title('NDWI Histogram with Otsu Threshold')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.tight_layout()\n",
        "#plt.show()\n",
        "\n",
        "# export\n",
        "# Save the plot as a JPEG image\n",
        "output_path = \"otsu_threshold_histogram.jpg\"\n",
        "plt.savefig(output_path, format='jpg', dpi=500)\n",
        "\n",
        "# Download the file from Colab\n",
        "files.download(output_path)"
      ],
      "metadata": {
        "id": "Kq0WzffkGeU-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 3.2 Visualize Otsu threshold water masks"
      ],
      "metadata": {
        "id": "EV3cvyoStoQw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ==== Visualize waterline masks =======\n",
        "\n",
        "# Convert the ImageCollection to a list and select a few images\n",
        "waterline_list = waterline_collection.toList(waterline_collection.size())\n",
        "\n",
        "# Select 3 example images (adjust indices as needed)\n",
        "example1 = ee.Image(waterline_list.get(16)).select('binary')\n",
        "example2 = ee.Image(waterline_list.get(10)).select('binary')\n",
        "example3 = ee.Image(waterline_list.get(0)).select('binary')\n",
        "\n",
        "vis_params = {\n",
        "    'min': 0,\n",
        "    'max': 1,\n",
        "    'palette': ['000000', '00FFFF']  # black background, cyan waterlines\n",
        "}\n",
        "\n",
        "Map.addLayer(example1, vis_params, 'Waterline 1')\n",
        "Map.addLayer(example2, vis_params, 'Waterline 2')\n",
        "Map.addLayer(example3, vis_params, 'Waterline 3')\n",
        "\n",
        "# Optionally center the map on one of the waterlines\n",
        "Map.centerObject(example1, 11)  # Zoom level 11 for context\n",
        "\n",
        "Map"
      ],
      "metadata": {
        "id": "kCgxglgpqHI7",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3.3 Apply Canny Edge Detection to extract shoreline based on Otsu's land/water layer."
      ],
      "metadata": {
        "id": "PUJU_MbbtvZ2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Create Shoreline Edges Using a Canny Edge Detector\n",
        "\n",
        "def detect_shoreline_edges(image):\n",
        "    binary = image.select('binary')\n",
        "\n",
        "    # Apply Canny edge detector\n",
        "    edges = ee.Algorithms.CannyEdgeDetector(binary, threshold=0.99, sigma=1.0)\n",
        "\n",
        "    # Optionally mask edges\n",
        "    edges = edges.updateMask(edges)\n",
        "\n",
        "    # Retain metadata and set an edge-specific property\n",
        "    return edges.set({\n",
        "        'system:time_start': image.get('system:time_start'),\n",
        "        'otsu_threshold': image.get('otsu_threshold')\n",
        "    })\n",
        "\n",
        "shoreline_edges = waterline_collection.map(detect_shoreline_edges)\n",
        "\n",
        "\n",
        "\n",
        "# Pick a few shoreline edge images\n",
        "sample_edges = shoreline_edges.toList(5)\n",
        "for i in range(5):\n",
        "    edge_image = ee.Image(sample_edges.get(i))\n",
        "    Map.addLayer(edge_image, {'palette': ['cyan']}, f'Shoreline Edge {i+1}')\n",
        "\n",
        "Map\n"
      ],
      "metadata": {
        "collapsed": true,
        "id": "5tOr_KbZdU9s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### Let's inspect 'shoreline_edges to make sure all metadata is there\n",
        "# Convert to list to inspect a few images\n",
        "sample_edges = shoreline_edges.toList(5)\n",
        "\n",
        "# Check bands and properties for each image\n",
        "for i in range(5):\n",
        "    image = ee.Image(sample_edges.get(i))\n",
        "    info = image.getInfo()\n",
        "\n",
        "    print(f\"Image {i+1}\")\n",
        "    print(\"Bands:\", [band['id'] for band in info['bands']])\n",
        "    print(\"Properties:\")\n",
        "    for key, val in info['properties'].items():\n",
        "        print(f\"  {key}: {val}\")\n",
        "    print(\"-\" * 30)\n",
        "\n",
        "for i in range(5):\n",
        "    image = ee.Image(sample_edges.get(i))\n",
        "    timestamp = ee.Date(image.get('system:time_start')).format('yyyy-MM-dd HH:mm')\n",
        "    print(f\"Image {i+1} timestamp: {timestamp.getInfo()}\")\n"
      ],
      "metadata": {
        "collapsed": true,
        "id": "O0h1-HDMoRKg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#=============== Checkpoint ===============================\n",
        "###Everything good up to this point (4/10/2025)\n",
        "##### Next:\n",
        "- add water level elevation data to shoreline_edges\n",
        "- vectorize\n",
        "- interpolate\n",
        "- generate and export DEM"
      ],
      "metadata": {
        "id": "IZxP3-WNpWuW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 4. Add elevation data to each shoreline/waterline"
      ],
      "metadata": {
        "id": "oRTgMCamszRj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 4.1 Extract timestamp and then create a .csv with water level data"
      ],
      "metadata": {
        "id": "yPQJBAXTuZlX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "##### Extract timestamps from images so that water level data can be manually assigned to corresponding dates and times.\n",
        "\n",
        "# Get list of all images in the waterline collection\n",
        "image_list = waterline_collection.toList(waterline_collection.size())\n",
        "\n",
        "# Function to extract timestamp for each image\n",
        "def get_time_info(i):\n",
        "    image = ee.Image(image_list.get(i))\n",
        "    time_start = ee.Date(image.get('system:time_start')).format('YYYY-MM-dd HH:mm:ss')\n",
        "    return time_start\n",
        "\n",
        "# Loop through and get timestamps\n",
        "timestamps = [get_time_info(i).getInfo() for i in range(image_list.size().getInfo())]\n",
        "\n",
        "# Display results in a table\n",
        "\n",
        "df = pd.DataFrame(timestamps, columns=['timestamp'])\n",
        "print(df)\n",
        "\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive/')\n",
        "\n",
        "# Export image timestamp to manually match water levels based on NOAA gauges\n",
        "'''\n",
        "df.to_csv('/content/gdrive/My Drive/RB_waterline_timestamps.csv', index=False)\n",
        "'''"
      ],
      "metadata": {
        "collapsed": true,
        "id": "l6lAMPHssD13"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 4.2 Match water level elevation data based on timestamp"
      ],
      "metadata": {
        "id": "2hFAByfduUUy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Note: Water levels for Rookery Bay were obtained from the 8724991 MARCO, BIG MARCO RIVER, FL NOAA gauge. Values were matched to landsat image date and time"
      ],
      "metadata": {
        "id": "wbxRX8HqHsVz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Load water level data for each image\n",
        "### Note that here, LM_waterline_timestamp.csv file was directly uploaded to GEE and then pulled from there as a FeatureCollection\n",
        "water_level_fc = ee.FeatureCollection('projects/ee-acantu/assets/RB_waterline_timestamps')\n",
        "print(water_level_fc.limit(5).getInfo()) # check format\n",
        "\n",
        "def add_timestamp_property(image):\n",
        "    # Extract the timestamp (system:time_start) as a date object\n",
        "    timestamp = ee.Date(image.get('system:time_start'))\n",
        "    # Format the timestamp as 'YYYY-MM-DD HH:mm:ss'\n",
        "    timestamp_str = timestamp.format('yyyy-MM-dd HH:mm')\n",
        "\n",
        "    # Transfer all properties from shoreline_edges and set the timestamp\n",
        "    image_properties = image.toDictionary()\n",
        "    image_with_timestamp = image.set('timestamp', timestamp_str)\n",
        "\n",
        "    # Ensure that all other properties from shoreline_edges are transferred\n",
        "    return image_with_timestamp.set(image_properties)\n",
        "\n",
        "# Apply this function to shoreline_edges collection\n",
        "shorelines_timestamp = shoreline_edges.map(add_timestamp_property)\n",
        "print(shorelines_timestamp.limit(5).getInfo()) # check timestamp\n",
        "\n",
        "# Function to add water level to each waterline based on timestamp matching\n",
        "def add_water_level_to_line(image):\n",
        "    # Get the timestamp from the image\n",
        "    timestamp = image.get('timestamp')\n",
        "\n",
        "    # Match the waterline timestamp to the tide gauge data\n",
        "    matched_tide_gauge = water_level_fc.filterMetadata('timestamp', 'equals', timestamp)\n",
        "\n",
        "    # Extract the water level if a match exists\n",
        "    water_level = ee.Algorithms.If(\n",
        "        matched_tide_gauge.size().gt(0),\n",
        "        matched_tide_gauge.first().get('WL'),\n",
        "        -9999  # Default value if no match\n",
        "    )\n",
        "\n",
        "    # Transfer all properties from the original image\n",
        "    image_properties = image.toDictionary()\n",
        "\n",
        "    # Set the water level as a property\n",
        "    image_with_water_level = image.set('water_level', water_level)\n",
        "\n",
        "    # Ensure that all other properties from shoreline_edges are transferred\n",
        "    return image_with_water_level.set(image_properties)\n",
        "\n",
        "# Apply the function to add water levels to each waterline\n",
        "waterlines_with_levels = shorelines_timestamp.map(add_water_level_to_line)\n",
        "print(waterlines_with_levels.limit(1).getInfo())\n",
        "\n",
        "# Check bands and properties for the first 3 images in waterlines_with_levels, along with their values\n",
        "image_list = waterlines_with_levels.toList(5)\n",
        "for i in range(3):\n",
        "    img = ee.Image(image_list.get(i))\n",
        "\n",
        "    # Get band names and their values\n",
        "    band_names = img.bandNames().getInfo()\n",
        "    print(f\"Image {i+1} Bands:\")\n",
        "    for band in band_names:\n",
        "        band_value = img.select(band).getInfo()  # Get the band values (e.g., as a list or dictionary)\n",
        "        print(f\"  Band: {band}, Value: {band_value}\")\n",
        "\n",
        "    # Get properties and their values\n",
        "    properties = img.propertyNames().getInfo()\n",
        "    print(f\"Image {i+1} Properties:\")\n",
        "    for prop in properties:\n",
        "        prop_value = img.get(prop).getInfo()  # Get the property value\n",
        "        print(f\"  Property: {prop}, Value: {prop_value}\")"
      ],
      "metadata": {
        "collapsed": true,
        "id": "63bkB_95uQt-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4.3 visualize waterlines after water level has been added"
      ],
      "metadata": {
        "id": "wVaw_ibxnDRU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Loop through the first 5 images and display them\n",
        "for i in range(5):\n",
        "    img = ee.Image(image_list.get(i))\n",
        "\n",
        "    # Add the 'binary' band as a layer to the map\n",
        "    Map.addLayer(img.select('binary'), {\n",
        "        'min': 0,\n",
        "        'max': 1,\n",
        "        'palette': ['blue', 'yellow']  # Change the palette for better visualization if needed\n",
        "    }, f\"Image {i+1}\")\n",
        "\n",
        "# Center the map to the region of interest (you can adjust the coordinates and zoom level)\n",
        "Map.centerObject(waterlines_with_levels, 12)  # Adjust zoom level if needed\n",
        "Map"
      ],
      "metadata": {
        "id": "cnuJCkHDOpuP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 4.4 convert to featureCollection to export as .shp"
      ],
      "metadata": {
        "id": "RuhSANqhMbgN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to convert binary waterlines into geometries\n",
        "def vectorize_waterline(image):\n",
        "    # Convert binary band to integer\n",
        "    binary_image = image.select('binary').toInt()\n",
        "\n",
        "    # Vectorize binary image\n",
        "    vectors = binary_image.reduceToVectors(\n",
        "        reducer=ee.Reducer.countEvery(),\n",
        "        geometryType='polygon',\n",
        "        scale=30,\n",
        "        eightConnected=True,\n",
        "        maxPixels=1e8\n",
        "    )\n",
        "\n",
        "    # Merge all polygons into one geometry\n",
        "    dissolved = vectors.geometry().dissolve(maxError=1)\n",
        "\n",
        "    # Build a single Feature with combined geometry and properties\n",
        "    return ee.Feature(dissolved).set({\n",
        "        'timestamp': image.get('timestamp'),\n",
        "        'water_level': image.get('water_level')\n",
        "    })\n",
        "\n",
        "\n",
        "# Apply the vectorization to the ImageCollection\n",
        "vectorized_waterlines = waterlines_with_levels.map(vectorize_waterline)\n",
        "\n",
        "# Inspect the result (first few features)\n",
        "vectorized_waterlines_info = vectorized_waterlines.limit(5).getInfo()\n",
        "\n",
        "# Print out geometry and properties for the first 5 vectorized waterlines\n",
        "for i, feature in enumerate(vectorized_waterlines_info['features']):\n",
        "    print(f\"Feature {i+1}:\")\n",
        "    print(\"  Properties:\", feature['properties'])  # This shows the properties (e.g., timestamp, water_level)\n",
        "\n",
        "\n",
        "\n",
        "# No need to flatten — each feature is already one waterline\n",
        "combined_vectorized_waterlines = ee.FeatureCollection(vectorized_waterlines)\n",
        "# Merge all the vectorized waterlines into a single FeatureCollection\n",
        "#combined_vectorized_waterlines = vectorized_waterlines.flatten()\n",
        "\n",
        "# Check the resulting FeatureCollection\n",
        "print(combined_vectorized_waterlines.size().getInfo())  # Number of features\n",
        "\n",
        "## Must export contour lines as .shp then upload again step 5.1 to create point cloud\n",
        "'''\n",
        "# Export the combined FeatureCollection to Google Drive as a Shapefile\n",
        "export_task = ee.batch.Export.table.toDrive(\n",
        "    collection=combined_vectorized_waterlines,\n",
        "    description='RB_waterlines_Contour',\n",
        "    fileFormat='SHP'\n",
        ")\n",
        "\n",
        "# Start the export task\n",
        "export_task.start()\n",
        "'''"
      ],
      "metadata": {
        "id": "HDqSpSosMYTI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4.5 Create contour map (19 lines from 19 images)"
      ],
      "metadata": {
        "id": "bIoybMVZzWdH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## There has to be 25 features (satellite images) in the FeatureCollection. Let's make sure\n",
        "\n",
        "# Get the number of features\n",
        "num_features = combined_vectorized_waterlines.size()\n",
        "print('Number of waterlines:', num_features.getInfo())\n",
        "\n",
        "# Get the first feature to inspect its properties and geometry type\n",
        "first = ee.Feature(combined_vectorized_waterlines.first())\n",
        "print('Properties of first feature:')\n",
        "print(first.toDictionary().getInfo())\n",
        "\n",
        "# Check the geometry type of the first feature\n",
        "print('Geometry type:', first.geometry().type().getInfo())"
      ],
      "metadata": {
        "id": "2Su4c-1JekGB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Visualize contour map"
      ],
      "metadata": {
        "id": "6_qNssbd-3Ho"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert float water levels to strings\n",
        "water_levels = combined_vectorized_waterlines.aggregate_array('water_level').distinct().sort()\n",
        "water_levels_str = water_levels.map(lambda wl: ee.String(ee.Number(wl)))\n",
        "\n",
        "# Generate color list in Python (still using matplotlib)\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.cm as cm\n",
        "import matplotlib.colors as colors\n",
        "\n",
        "num_levels = water_levels.length().getInfo()\n",
        "cmap = cm.get_cmap('viridis', num_levels)\n",
        "color_list = [colors.to_hex(cmap(i)) for i in range(cmap.N)]\n",
        "\n",
        "# Create dictionary of water_level (as string) to color\n",
        "wl_color_dict = ee.Dictionary.fromLists(water_levels_str, ee.List(color_list))\n",
        "\n",
        "# Assign a color to each feature using its water_level\n",
        "def add_color(feature):\n",
        "    wl_str = ee.String(ee.Number(feature.get('water_level')))\n",
        "    color = wl_color_dict.get(wl_str)\n",
        "    return feature.set({'style': {'color': color, 'width': 1}})\n",
        "\n",
        "styled_fc = combined_vectorized_waterlines.map(add_color)\n",
        "\n",
        "# Add styled features to map\n",
        "Map.addLayer(\n",
        "    styled_fc.style(**{'styleProperty':'style'}),\n",
        "    {},\n",
        "    'Waterlines Colored by Water Level'\n",
        ")\n",
        "#Map.centerObject(styled_fc, 10)\n",
        "Map\n",
        "\n"
      ],
      "metadata": {
        "id": "Qfm4l36h5LCT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 5. Steps to perform Interpolation. via IDW (inverse distance weighting) or Kriging"
      ],
      "metadata": {
        "id": "EVUL9rk65OVd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 5.1 Sample points (point cloud) from waterline polygons and Interpolate to generate DEM"
      ],
      "metadata": {
        "id": "vNfz2y0J_nS7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###### NOTE: saple points and interpolation will be done outside of GEE usin python only. Thus, the exported contour line shapefile must be imported."
      ],
      "metadata": {
        "id": "p2BsNm6zXumk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import geopandas as gpd\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.interpolate import griddata\n",
        "from shapely.geometry import Point, LineString, Polygon, MultiPolygon, MultiLineString\n",
        "from scipy.spatial import distance\n",
        "\n",
        "from google.colab import files\n",
        "uploaded = files.upload()  # Upload all files related to the shapefile (LM_waterlines_Contour)\n",
        "##### NOTE: make sure to select all 5-6 files (shx, shp, prj, dbf, etc.)\n",
        "# Load the shapefile into GeoPandas\n",
        "gdf = gpd.read_file(\"RB_waterlines_Contour.shp\")  # Adjust filename if different\n",
        "gdf = gdf.to_crs(epsg=4326)  # Project to UTM zone 14N or whatever fits your area best\n",
        "\n",
        "gdf_2 = gpd.read_file(\"Intertidal_NDWI_STD_RB.shp\")\n",
        "gdf_2 = gdf_2.to_crs(epsg=4326)\n",
        "\n",
        "gdf_3 = gdf.clip(gdf_2)"
      ],
      "metadata": {
        "id": "I_ikAdck_Lnm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# List to store sampled points and water levels\n",
        "sample_points = []\n",
        "water_levels = []\n",
        "\n",
        "for idx, row in gdf.iterrows():\n",
        "    geom = row.geometry\n",
        "    level = row['water_leve']  # Replace with actual field name if different\n",
        "\n",
        "    # Handle different geometry types\n",
        "    if isinstance(geom, (Polygon, MultiPolygon)):\n",
        "        # Handle Polygon and MultiPolygon geometries\n",
        "        polygons = [geom] if isinstance(geom, Polygon) else list(geom.geoms)\n",
        "        for poly in polygons:\n",
        "            for coord in poly.exterior.coords:\n",
        "                sample_points.append(coord)\n",
        "                water_levels.append(level)\n",
        "\n",
        "            # If there are holes (interiors), handle those too\n",
        "            for interior in poly.interiors:\n",
        "                for coord in interior.coords:\n",
        "                    sample_points.append(coord)\n",
        "                    water_levels.append(level)\n",
        "\n",
        "    elif isinstance(geom, (LineString, MultiLineString)):\n",
        "        # Handle LineString and MultiLineString geometries\n",
        "        lines = [geom] if isinstance(geom, LineString) else list(geom.geoms)\n",
        "        for line in lines:\n",
        "            for coord in line.coords:\n",
        "                sample_points.append(coord)\n",
        "                water_levels.append(level)\n",
        "\n",
        "# Convert sample points and water levels into a GeoDataFrame\n",
        "sample_points_gdf = gpd.GeoDataFrame(geometry=gpd.points_from_xy(*zip(*sample_points)),\n",
        "                                     data={'water_level': water_levels},\n",
        "                                     crs=\"EPSG:4326\")  # Ensure CRS is correct for your dataset\n",
        "\n",
        "## Visualize sample points\n",
        "# Plot the points\n",
        "fig, ax = plt.subplots(figsize=(10, 10))\n",
        "sample_points_gdf.plot(ax=ax, color='blue', markersize=2, label='Sample Points')\n",
        "\n",
        "# Optionally, you can also plot the waterlines (if needed)\n",
        "gdf.plot(ax=ax, color='black', alpha=0.5, linewidth=0.5, label='Waterlines')\n",
        "\n",
        "plt.legend()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "zHGmMgX1Jupn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Export the sample points GeoDataFrame to a shapefile\n",
        "# sample_points_gdf.to_file(\"/content/gdrive/My Drive/RB_sample_points2.shp\")"
      ],
      "metadata": {
        "id": "6M6P2KmVU71k",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Checkpoint: Workflow ends here after point cloud is exported. As of April 2025, interpolation via Kriging is applied in ArcGIS Pro."
      ],
      "metadata": {
        "id": "q_o8FkiFepXp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "### KRIGING APPROACH April 14, 2025\n",
        "'''\n",
        "# Extract coordinates and water level values from GeoDataFrame\n",
        "sample_coords = np.array([(point.x, point.y) for point in sample_points_gdf.geometry])\n",
        "sample_values = np.array(sample_points_gdf['water_level'])  # Replace with correct column name\n",
        "\n",
        "# Define grid spacing (approx. 10m resolution)\n",
        "xmin, ymin, xmax, ymax = sample_points_gdf.total_bounds\n",
        "grid_spacing = 10  # meters\n",
        "\n",
        "# Generate grid (assumes your coordinates are in meters)\n",
        "grid_x = np.arange(xmin, xmax, grid_spacing)\n",
        "grid_y = np.arange(ymin, ymax, grid_spacing)\n",
        "grid_xx, grid_yy = np.meshgrid(grid_x, grid_y)\n",
        "'''"
      ],
      "metadata": {
        "id": "BRytJ3zS5jSq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Ordinary Kriging\n",
        "'''\n",
        "OK = OrdinaryKriging(\n",
        "    sample_coords[:, 0],  # x\n",
        "    sample_coords[:, 1],  # y\n",
        "    sample_values,        # z (water level)\n",
        "    variogram_model='linear',  # or 'spherical', 'gaussian', 'exponential'\n",
        "    verbose=False,\n",
        "    enable_plotting=False\n",
        ")\n",
        "\n",
        "# Execute on the grid\n",
        "#z_kriged, ss = OK.execute('grid', grid_x, grid_y)\n",
        "'''"
      ],
      "metadata": {
        "id": "6nK3VMxV57-q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ======== CHECKPOINT =========== April 11, 2025\n",
        "#### Interpolation in QGIS and/or ArcGIS Pro was successful, but I still can't get the interpolation in python. RAM memory issue using Kriging method"
      ],
      "metadata": {
        "id": "8iTKixRvrDvs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "'''\n",
        "# IDW interpolation function\n",
        "def idw_interpolation(points, values, grid_x, grid_y, power=2):\n",
        "    # Create a mesh grid for the target locations\n",
        "    grid_coords = np.array([grid_x.flatten(), grid_y.flatten()]).T\n",
        "\n",
        "    # Calculate the distances between the grid points and sample points\n",
        "    dist = distance.cdist(grid_coords, points)\n",
        "\n",
        "    # Prevent division by zero (if a point is too close, set a minimum distance)\n",
        "    dist[dist == 0] = 1e-10\n",
        "\n",
        "    # Compute the weights using inverse distance\n",
        "    weights = 1 / (dist ** power)\n",
        "\n",
        "    # Normalize the weights to sum to 1\n",
        "    weights /= weights.sum(axis=1)[:, np.newaxis]\n",
        "\n",
        "    # Perform the weighted average\n",
        "    grid_z = np.dot(weights, values)\n",
        "\n",
        "    # Reshape to match the grid size\n",
        "    return grid_z.reshape(grid_x.shape)\n",
        "\n",
        "\n",
        "# List to store sampled points and water levels\n",
        "sample_points = []\n",
        "water_levels = []\n",
        "\n",
        "# Extract sample points and corresponding water levels\n",
        "for idx, row in gdf.iterrows():\n",
        "    geom = row.geometry\n",
        "    level = row['water_leve']  # Replace with actual field name if different\n",
        "\n",
        "    # Handle different geometry types\n",
        "    if isinstance(geom, (Polygon, MultiPolygon)):\n",
        "        polygons = [geom] if isinstance(geom, Polygon) else list(geom.geoms)\n",
        "        for poly in polygons:\n",
        "            for coord in poly.exterior.coords:\n",
        "                sample_points.append(coord)\n",
        "                water_levels.append(level)\n",
        "\n",
        "            # If there are holes (interiors), handle those too\n",
        "            for interior in poly.interiors:\n",
        "                for coord in interior.coords:\n",
        "                    sample_points.append(coord)\n",
        "                    water_levels.append(level)\n",
        "\n",
        "    elif isinstance(geom, (LineString, MultiLineString)):\n",
        "        lines = [geom] if isinstance(geom, LineString) else list(geom.geoms)\n",
        "        for line in lines:\n",
        "            for coord in line.coords:\n",
        "                sample_points.append(coord)\n",
        "                water_levels.append(level)\n",
        "\n",
        "# Convert to numpy arrays for interpolation\n",
        "coordinates = np.array(sample_points)\n",
        "values = np.array(water_levels)\n",
        "\n",
        "# Define the grid for interpolation (10m resolution)\n",
        "xmin, ymin, xmax, ymax = gdf.total_bounds\n",
        "grid_x, grid_y = np.mgrid[xmin:xmax:10j, ymin:ymax:10j]  # 1resolution\n",
        "\n",
        "# Perform IDW interpolation\n",
        "grid_z = idw_interpolation(coordinates, values, grid_x, grid_y, power=2)\n",
        "\n",
        "# Mask NaN values if any\n",
        "grid_z = np.ma.masked_invalid(grid_z)\n",
        "\n",
        "# Plot the result\n",
        "plt.figure(figsize=(10, 8))\n",
        "plt.imshow(grid_z, extent=(xmin, xmax, ymin, ymax), origin='lower', cmap='terrain')\n",
        "plt.colorbar(label='Water Level')\n",
        "plt.title('Interpolated DEM (10m resolution)')\n",
        "plt.xlabel('Longitude')\n",
        "plt.ylabel('Latitude')\n",
        "\n",
        "# Display plot\n",
        "plt.show()\n",
        "'''"
      ],
      "metadata": {
        "id": "eWSgtGxrLmE0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Export DEM"
      ],
      "metadata": {
        "id": "_4qgr9tNM8s3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "\n",
        "#!pip install rasterio\n",
        "import rasterio\n",
        "from rasterio.transform import from_origin\n",
        "\n",
        "# Extract the coordinates and water levels\n",
        "coordinates = np.array([point.coords[0] for point in gdf.geometry])\n",
        "water_levels = gdf['water_leve'].values\n",
        "\n",
        "# Step 2: Define the grid for interpolation (10m resolution)\n",
        "xmin, ymin, xmax, ymax = gdf.total_bounds\n",
        "grid_x, grid_y = np.mgrid[xmin:xmax:10, ymin:ymax:10]  # 10m resolution grid\n",
        "\n",
        "# Step 3: Perform interpolation using IDW (or other method)\n",
        "grid_z = griddata(coordinates, water_levels, (grid_x, grid_y), method='cubic')\n",
        "\n",
        "# Step 4: Create the GeoTIFF\n",
        "# Define the transform (top-left corner and pixel size)\n",
        "transform = from_origin(xmin, ymax, 10, 10)  # 10m resolution, starting at (xmin, ymax)\n",
        "\n",
        "# Step 5: Save as a GeoTIFF\n",
        "output_raster_path = '/content/drive/MyDrive/DEM_output_10m_resolution.tif'\n",
        "\n",
        "# Create the raster file\n",
        "with rasterio.open(output_raster_path, 'w', driver='GTiff', height=grid_z.shape[0], width=grid_z.shape[1],\n",
        "                   count=1, dtype='float32', crs='EPSG:32614', transform=transform) as dst:\n",
        "    dst.write(grid_z, 1)\n",
        "\n",
        "print(f\"DEM has been saved as a GeoTIFF: {output_raster_path}\")\n",
        "'''"
      ],
      "metadata": {
        "id": "4NU6-7gBNH0C"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}